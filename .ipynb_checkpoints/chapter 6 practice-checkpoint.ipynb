{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T01:30:46.342792Z",
     "start_time": "2020-07-29T01:30:45.214710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 20\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 ##\n",
    "- read in a csv file that has headers.\n",
    "- read in another csv file that does not have headers and assign column names in the read statement. Make one of the columns the index.\n",
    "- read in a csv with missing values that will convert them to `NaN`. Try it with different sentinel values in different columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:08:33.920987Z",
     "start_time": "2020-08-01T06:08:33.856984Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 ##\n",
    "- Read in only the first few rows of a csv file, skipping some of the rows.\n",
    "- Write a subset of columns from that `DataFrame` out to a new csv file using different sentinel values, different delimiter, and no index.\n",
    "- Read in a csv file in chunks. Write each chunk out to a different csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T06:40:07.193378Z",
     "start_time": "2020-08-01T06:40:07.142388Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 ##\n",
    "- (built in `json` module) \n",
    "- read json `data/usdoj_data_list.json` files into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T02:05:29.640828Z",
     "start_time": "2020-07-31T02:05:29.547823Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 ##\n",
    "- (install modules `lxml`, `beautifulsoup4`, `html5lib`)\n",
    "- read table(s) from a website into a `DataFrame` objects (for example, [https://www.tide-forecast.com/locations/Date/tides/latest](https://www.tide-forecast.com/locations/Date/tides/latest))\n",
    "- Select one of the data frames and calculate the frequencies of the values in one of the columns\n",
    "- save the dataframe in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T02:17:15.360162Z",
     "start_time": "2020-08-01T02:17:14.103275Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 ##\n",
    "- (install module `lxml`)\n",
    "- load `data/books.xml` into a `DataFrame`\n",
    "- save the `DataFrame` in a hdf5 file \n",
    "- read from the open hdf5 file directly using the object label you assigned\n",
    "- close the store then open the hdf5 file and read in the data\n",
    "- (more on hdf5 with pandas: [https://medium.com/@jerilkuriakose/using-hdf5-with-python-6c5242d08773](https://medium.com/@jerilkuriakose/using-hdf5-with-python-6c5242d08773))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T02:57:44.771536Z",
     "start_time": "2020-08-01T02:57:44.651528Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 ##\n",
    "- (install modules `xlrd`, `openpyxl`)\n",
    "- create a table in an Excel file, then read it into a  `DataFrame`.\n",
    "- Manipulate the dataframe and save it to a new workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:12:21.404489Z",
     "start_time": "2020-08-01T04:12:21.332484Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 ##\n",
    "- read from API (install `requests` module)\n",
    "- select a free API to use, here is a list of free APIs (most will require creating an account to get access to the API): [https://github.com/public-apis/public-apis](https://github.com/public-apis/public-apis) \n",
    "- (install modules `xlrd`, `openpyxl`)\n",
    "- save the `DataFrame` in a new Excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T05:44:34.219305Z",
     "start_time": "2020-08-01T05:44:33.903866Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8 ##\n",
    "- (install module `sqlalchemy`)\n",
    "- Use the built in `sqlite3` package to create a sql table.\n",
    "- use the same package to query a subset of rows from the sql table, then load them into a `DataFrame`.\n",
    "- Use the `sqlalchemy` package to load a different subset of rows directly into a `DataFrame`.\n",
    "- Delete the table and close the connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T05:35:48.512587Z",
     "start_time": "2020-08-01T05:35:48.461581Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
